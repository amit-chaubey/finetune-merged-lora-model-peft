{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "sQHHSSqt-Jl4",
    "outputId": "956e17c7-dda1-4c42-c6bf-5a51f39372fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Collecting trl\n",
      "  Downloading trl-0.19.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (0.33.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: transformers>=4.51.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.53.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (1.1.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.6.15)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.0->trl) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.0->trl) (0.21.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
      "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.19.0-py3-none-any.whl (375 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m129.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, datasets, bitsandbytes, trl\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.4\n",
      "    Uninstalling datasets-2.14.4:\n",
      "      Successfully uninstalled datasets-2.14.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bitsandbytes-0.46.1 datasets-3.6.0 fsspec-2025.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 trl-0.19.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "8ee18cea3fc545829bdc548dcad8f314",
       "pip_warning": {
        "packages": [
         "datasets",
         "fsspec",
         "nvidia"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install datasets bitsandbytes trl huggingface-hub accelerate safetensors pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xaaffU0cCSWL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "13896a3dcc9a455991e1a4c0d7176a14",
      "b3d2c1abe0d04b58adf52d08f74a2dc5",
      "5194e10dbe1e47c8b57f5b560521bb5e",
      "8d7fce6eb08d40e6b9b820776bcce9fb",
      "3690e2df291e4d94af5db2bf7ad8f9cb",
      "393034a5c6c24f2981ff630ded073dde",
      "e66cdda7526e4c7fb70de66087b70b02",
      "f878d07b104a43f09b9e7b5332719c7d",
      "35c07860255d4e67b50fa408bdff6164",
      "7027d139f4194fb1aef0df7de6b47e0c",
      "661d3929dcac44f3a238364d43a932bd",
      "b28b6b9edb8642f8b54d438cb982d817",
      "8333d134eb834a3a81748e265132fedc",
      "d759b6d5f5fa46cb8e2e071d4e457a16",
      "62a99c82f862424d88f02d795bdc3eb0",
      "10894f9e7b364daca6bf706a40bb92e1",
      "8d3788afa56344f2914417a4d7429f41",
      "0f57f7b2148940539f745ff4bce78e27",
      "284fbc1d10ba4271824ba5394e4caff8",
      "151e89f9f76e4d87bad87948bef14acc",
      "eb56511a9b6b4193867a7d2811410eeb",
      "fbf89a869eaf4ac383665ce1c87111b4",
      "b6f066dd6a2b42a69fc3add37e090069",
      "0b5ba7be613a4aaba1904a372839d787",
      "4e344b8bd3ac4399bfb59c14e5df5e26",
      "359ed933382445fc9c5a9e564ef092be",
      "025c8dd797254b068fa685a057d1ce58",
      "3a4974c39fac4eee953835943c13ff83",
      "2c379512f6d04033b849d85f307e1b0c",
      "9c6861e8eedf48149ab6fab5a9737c80",
      "fbe360dd0ccf4eebbede0e51051bc4b3",
      "9b49240465ee4efda2e6d41948c1f376",
      "ba90debcf5d343b68264b0adf7297aef",
      "5caa06fe725a44f29c5b7f7e513e65b7",
      "01705b0d9112467c8379703df8b85079",
      "5dc577ac174a48c692c06e9f5519594a",
      "0064c21546e54c769f27a72b74f672bb",
      "0bf599a4496c44a6b8d5f8ba14fb2da5",
      "6ba3fe05385b4ea0b5ca14d7703f3545",
      "ee4df16d7ecf4975a38127bd7cc89e61",
      "eb3913b00de54289a1c03412e1ec2513",
      "4b41f8b57302481aa3bc64a208885a16",
      "0a7d57fb7da44012b215a55a32d1271c",
      "81dfa8ea208544388a462a1ccfdc19c6",
      "18be633290fc4c4e9664095efcdebdbb",
      "c27b0fb46fc643b5901e55bc025270b1",
      "697dfe72907a4615835aeaf1264ea378",
      "0ee176388f6c44249decb4d7dd16fdda",
      "ef797995f3db4024aa343b2a877561ad",
      "c91a451ae4de4a67aea9c318f7f437b4",
      "9af23966d4894c73bc583ec2ae82c923",
      "b2972d6300ba4dca9b434ef683c56f99",
      "66f47d40b59549138ff8d7afdf59a3b5",
      "17a9538a1f5240ec9217139ceb60c466",
      "f54b272d74bb45489fd25fb4cb30e716",
      "fe4599e4108140a3af1d3c93f85125fd",
      "24995964b67b4e41ac16788f1800f4a1",
      "f676d41343b44598aa6a1ffffdde93de",
      "2a1a4539e4834667a46f16ecebe6218c",
      "b07a1670ad07451282967f8b905ab485",
      "844f476d66a5491eb48bf5691772fa9b",
      "cb76e5950aac4ccc86ee698d83fbc4c8",
      "427acbef829a4c989b0300d99874564b",
      "9b286dc1392d4356b1a957977b1b187f",
      "1da0d44ec9c24da6ab19edd2ea6ef153",
      "9f086bdfd41041a69762370003269ff9",
      "b4341b476ea54f039e6e87bc6fd96d77",
      "b1fdac0310a54fddbb43219a480e075f",
      "6ccda40b26bb4d34b1f351576ae27b39",
      "0936997a74504e4b9192fc23d3c50452",
      "9ecade278ec14d69a072cd8665529865",
      "9994b2d25aa045988f770bec44adaafe",
      "982574b6dc804aa8b99b38bcc6378ae3",
      "1a3a00981e834668b42e3d00cc112aee",
      "d8e0c01397194d3589542121684bd778",
      "2e5f4791d39646f8b4775248e208e10b",
      "c31f2eb6cb6e43a6b9b27cabca3bd8ad"
     ]
    },
    "id": "XB_JtzX0DH1m",
    "outputId": "f10be114-3b38-462e-b398-29322df14b90"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13896a3dcc9a455991e1a4c0d7176a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28b6b9edb8642f8b54d438cb982d817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f066dd6a2b42a69fc3add37e090069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5caa06fe725a44f29c5b7f7e513e65b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18be633290fc4c4e9664095efcdebdbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4599e4108140a3af1d3c93f85125fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4341b476ea54f039e6e87bc6fd96d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type= \"nf4\",\n",
    "    bnb_4bit_compute_dtype= torch.float32,\n",
    "    bnb_4bit_use_double_quant= True\n",
    "    )\n",
    "repo = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(repo, quantization_config= bnb_config, device_map= \"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404,
     "referenced_widgets": [
      "6f328f1e805449ee8aa63282df93d482",
      "0c85b3f702004440a421c4f67a4ca237",
      "df9a74c2acc14a40b8cfe8bed7009bd7",
      "db49e3d01e1741c8bc55e57c42c0f24a",
      "8842adb0d57f493caaf42a17ba27e596",
      "65ca5dd5294c4308b10e0e1efb2fdc2b",
      "ea4b49ff735f4055be8c24fb2ccdd8e6",
      "7ee8c51ea6f746859d0ee258b21535d8",
      "1e6faca447434d00b29b78b73bb21e78",
      "295563ece6a94e758d20f942d76b600f",
      "4631897f39994eac86da61a10d233f1c",
      "ceb7e7d942434603baf5561c64ed8c1a",
      "a8d7da6743de42098ea1511a02b14e5a",
      "b42ee9b551064407a6505fe22e22f306",
      "e8ef9017892c49cda1fb81c9bc8068f6",
      "51083ac33e0f4ee7a1b35df7b35e1798",
      "bed5aa7765714923ab7dde7b8fd16bc4",
      "bcb079167a1949c3ac5fda9208077e35",
      "35dc7f78cbee4057ab6a97889c1e435d",
      "8a2f8eee538547c8b7e673c558b35c91",
      "2b29a2f2c0b34629b8af0d0191356950",
      "7528a71900424a8abe2ff229904677b5",
      "94343f5f80f8432c93500b52ce54f8c6",
      "05289a93b07a4d00bbc61e578aec735a",
      "e26a2d11ac8649f994c008d1bd488a03",
      "c20aab3015554670a31593464e938967",
      "e16e66546aff472ab4b3a38a54e51b64",
      "07c5b304ae9243828910c0dac5b5b931",
      "f124826ed3d04989bf2f44f9a4eef2fd",
      "ecb428438801443b8043ce570c0bd6f9",
      "ca05fc0029fa4242825b60e36575dba8",
      "469dd301fea54976acd39acb61bd8936",
      "c955ab4a17144281a4802c0e703effc0",
      "b3b332d5c4be489d859e3c89f5cff884",
      "ca67df6d67504506bdf6b118660e93c8",
      "a11928eb8bce431d94125f8d6a8dc63e",
      "17f30154fc7149bcb08a92e2481e0619",
      "f25ee0daa95741b8be2e39764df5d1cb",
      "90b2e233cc9b48e28de1f0e3ab04bfcc",
      "d28e1f702d81488280db9557c5a40e77",
      "384fc791dcb34587bf5d77b85e8f954f",
      "dc6027e3fa0c4fa4b3779a546c79109f",
      "19645b8be7a74569a6eb9105a0ba0a43",
      "25c478b133d54bb4b96e939f77d38007",
      "e05be2313a29496eb32170d2212d43df",
      "a18127c577a94795ac0c344e5093894e",
      "74e43ee482394ba68d78efd9fe30e5f1",
      "0f26f375995544a2821f0ad42d77949a",
      "7c761aefc78d46beaee567f44442a38c",
      "ecbdc09eb9cd46779dcebc11cb906e42",
      "26f5dfe7e3574cbbbdf5efd9f97fe92e",
      "551fc560c13c43f8b2fae90e92183f79",
      "475f1cc8e0514e56abaed9a063a1ca5c",
      "77a080b7f0bd49e6b1ce6c4b55f4315f",
      "78dc21361ebf47d7a424d39db807a115",
      "3f8050e3d35e41f689b3f688f04d7eac",
      "af8669fbefb6424aa25c3646c853c07f",
      "0f93c93d47b14402887bb730f6619979",
      "8fab82060d294880b3e8ddbc558029df",
      "b9afe560182c4d94831d0c352d35520b",
      "de75e6c0cb1647588d05a43d35102090",
      "fc49a7824b11474aa423b31edcd7002e",
      "372bd5a1e55943dab9344f67f3f48509",
      "26b6fe5a13ec4626b8ea2aed8f7d911f",
      "61d75957d8ee4c3eb93037c62db5e184",
      "ad6ad18a6ebe4b99ab9428f69d253e8c",
      "a21df4cf8f86460191339087d5375382",
      "699d273a8937453e8dab709c8cd9f9c8",
      "32ea5a1170d94f63a8965f9295099722",
      "baa503b94fe44159b530a0d70d25dca4",
      "8492ee04cc604642ab6fb1f227798a58",
      "62993273bacc4981bb839a812e3c8cae",
      "17f987b6ab744c918eb9b80bdf22d2ab",
      "92a0ca0d7bdd49e1a6290d74e9e184bb",
      "682edcc5b3b44b16a8752cfcccdaeb0f",
      "03aef82a4f284668ad97c25a5b096753",
      "ad86887d4f46422898c88c20acbefa07"
     ]
    },
    "collapsed": true,
    "id": "dnqd-dgmFvKf",
    "outputId": "d4ec5425-62a8-4a4b-bc7d-28e7b7054874"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f328f1e805449ee8aa63282df93d482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb7e7d942434603baf5561c64ed8c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94343f5f80f8432c93500b52ce54f8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b332d5c4be489d859e3c89f5cff884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05be2313a29496eb32170d2212d43df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8050e3d35e41f689b3f688f04d7eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21df4cf8f86460191339087d5375382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# torch.random.manual_seed(0)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "#     device_map=\"cuda\",\n",
    "#     torch_dtype=\"auto\",\n",
    "#     trust_remote_code=True,\n",
    "# )\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"},\n",
    "#     {\"role\": \"assistant\", \"content\": \"Sure! Here are some ways to eat bananas and dragonfruits together: 1. Banana and dragonfruit smoothie: Blend bananas and dragonfruits together with some milk and honey. 2. Banana and dragonfruit salad: Mix sliced bananas and dragonfruits together with some lemon juice and honey.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"What about solving an 2x + 3 = 7 equation?\"},\n",
    "# ]\n",
    "\n",
    "# pipe = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "\n",
    "# generation_args = {\n",
    "#     \"max_new_tokens\": 500,\n",
    "#     \"return_full_text\": False,\n",
    "#     \"temperature\": 0.0,\n",
    "#     \"do_sample\": False,\n",
    "# }\n",
    "\n",
    "# output = pipe(messages, **generation_args)\n",
    "# print(output[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee3M9pnjEUaW",
    "outputId": "b4fd98f9-04f3-4d87-c64e-9074aa615e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2104.1310424804688\n"
     ]
    }
   ],
   "source": [
    "print(model.get_memory_footprint()/1024/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRZA6aC4HXk4",
    "outputId": "098f4ab9-34b4-4e24-e0c4-e461989faba9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phi3ForCausalLM(\n",
       "  (model): Phi3Model(\n",
       "    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x Phi3DecoderLayer(\n",
       "        (self_attn): Phi3Attention(\n",
       "          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "          (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n",
       "        )\n",
       "        (mlp): Phi3MLP(\n",
       "          (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "          (activation_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): Phi3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XPoMdAY4JDbP",
    "outputId": "a0c4f9d9-618e-4c6a-cbcf-f60807f2decf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): PeftModelForCausalLM(\n",
       "      (base_model): LoraModel(\n",
       "        (model): PeftModelForCausalLM(\n",
       "          (base_model): LoraModel(\n",
       "            (model): PeftModelForCausalLM(\n",
       "              (base_model): LoraModel(\n",
       "                (model): PeftModelForCausalLM(\n",
       "                  (base_model): LoraModel(\n",
       "                    (model): Phi3ForCausalLM(\n",
       "                      (model): Phi3Model(\n",
       "                        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "                        (layers): ModuleList(\n",
       "                          (0-31): 32 x Phi3DecoderLayer(\n",
       "                            (self_attn): Phi3Attention(\n",
       "                              (o_proj): lora.Linear4bit(\n",
       "                                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                                (lora_dropout): ModuleDict(\n",
       "                                  (default): Dropout(p=0.05, inplace=False)\n",
       "                                )\n",
       "                                (lora_A): ModuleDict(\n",
       "                                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                                )\n",
       "                                (lora_B): ModuleDict(\n",
       "                                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                                )\n",
       "                                (lora_embedding_A): ParameterDict()\n",
       "                                (lora_embedding_B): ParameterDict()\n",
       "                                (lora_magnitude_vector): ModuleDict()\n",
       "                              )\n",
       "                              (qkv_proj): lora.Linear4bit(\n",
       "                                (base_layer): Linear4bit(in_features=3072, out_features=9216, bias=False)\n",
       "                                (lora_dropout): ModuleDict(\n",
       "                                  (default): Dropout(p=0.05, inplace=False)\n",
       "                                )\n",
       "                                (lora_A): ModuleDict(\n",
       "                                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                                )\n",
       "                                (lora_B): ModuleDict(\n",
       "                                  (default): Linear(in_features=8, out_features=9216, bias=False)\n",
       "                                )\n",
       "                                (lora_embedding_A): ParameterDict()\n",
       "                                (lora_embedding_B): ParameterDict()\n",
       "                                (lora_magnitude_vector): ModuleDict()\n",
       "                              )\n",
       "                            )\n",
       "                            (mlp): Phi3MLP(\n",
       "                              (gate_up_proj): lora.Linear4bit(\n",
       "                                (base_layer): Linear4bit(in_features=3072, out_features=16384, bias=False)\n",
       "                                (lora_dropout): ModuleDict(\n",
       "                                  (default): Dropout(p=0.05, inplace=False)\n",
       "                                )\n",
       "                                (lora_A): ModuleDict(\n",
       "                                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                                )\n",
       "                                (lora_B): ModuleDict(\n",
       "                                  (default): Linear(in_features=8, out_features=16384, bias=False)\n",
       "                                )\n",
       "                                (lora_embedding_A): ParameterDict()\n",
       "                                (lora_embedding_B): ParameterDict()\n",
       "                                (lora_magnitude_vector): ModuleDict()\n",
       "                              )\n",
       "                              (down_proj): lora.Linear4bit(\n",
       "                                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                                (lora_dropout): ModuleDict(\n",
       "                                  (default): Dropout(p=0.05, inplace=False)\n",
       "                                )\n",
       "                                (lora_A): ModuleDict(\n",
       "                                  (default): Linear(in_features=8192, out_features=8, bias=False)\n",
       "                                )\n",
       "                                (lora_B): ModuleDict(\n",
       "                                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                                )\n",
       "                                (lora_embedding_A): ParameterDict()\n",
       "                                (lora_embedding_B): ParameterDict()\n",
       "                                (lora_magnitude_vector): ModuleDict()\n",
       "                              )\n",
       "                              (activation_fn): SiLU()\n",
       "                            )\n",
       "                            (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "                            (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "                            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "                            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "                          )\n",
       "                        )\n",
       "                        (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "                        (rotary_emb): Phi3RotaryEmbedding()\n",
       "                      )\n",
       "                      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "config = LoraConfig(\n",
    "    r = 8,\n",
    "    bias = \"none\",\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0.05,\n",
    "    target_modules = [\"query_key_value\", \"o_proj\", \"qkv_proj\", \"gate_up_proj\", \"down_proj\"],\n",
    "    task_type = \"CAUSAL_LM\"\n",
    "\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_Lxz8fPMuhX",
    "outputId": "1b513c00-cffe-4a68-8d65-8317b92d886a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2528.2619018554688\n"
     ]
    }
   ],
   "source": [
    "print(model.get_memory_footprint()/1024/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wDx5hjxXM6ZS",
    "outputId": "c8623789-bdb4-4186-d132-252da7d4e69a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method PeftModel.get_base_model of PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): PeftModelForCausalLM(\n",
      "      (base_model): LoraModel(\n",
      "        (model): PeftModelForCausalLM(\n",
      "          (base_model): LoraModel(\n",
      "            (model): PeftModelForCausalLM(\n",
      "              (base_model): LoraModel(\n",
      "                (model): PeftModelForCausalLM(\n",
      "                  (base_model): LoraModel(\n",
      "                    (model): Phi3ForCausalLM(\n",
      "                      (model): Phi3Model(\n",
      "                        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
      "                        (layers): ModuleList(\n",
      "                          (0-31): 32 x Phi3DecoderLayer(\n",
      "                            (self_attn): Phi3Attention(\n",
      "                              (o_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                              (qkv_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=3072, out_features=9216, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=9216, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                            )\n",
      "                            (mlp): Phi3MLP(\n",
      "                              (gate_up_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=3072, out_features=16384, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=16384, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                              (down_proj): lora.Linear4bit(\n",
      "                                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
      "                                (lora_dropout): ModuleDict(\n",
      "                                  (default): Dropout(p=0.05, inplace=False)\n",
      "                                )\n",
      "                                (lora_A): ModuleDict(\n",
      "                                  (default): Linear(in_features=8192, out_features=8, bias=False)\n",
      "                                )\n",
      "                                (lora_B): ModuleDict(\n",
      "                                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
      "                                )\n",
      "                                (lora_embedding_A): ParameterDict()\n",
      "                                (lora_embedding_B): ParameterDict()\n",
      "                                (lora_magnitude_vector): ModuleDict()\n",
      "                              )\n",
      "                              (activation_fn): SiLU()\n",
      "                            )\n",
      "                            (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
      "                            (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
      "                            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "                            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "                          )\n",
      "                        )\n",
      "                        (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
      "                        (rotary_emb): Phi3RotaryEmbedding()\n",
      "                      )\n",
      "                      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.get_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1xiTbhpNGYd",
    "outputId": "d9c58b8b-e715-4b6e-bd8e-e89ab22d3935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2651.074752\n"
     ]
    }
   ],
   "source": [
    "print(model.get_memory_footprint()/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnvrkrmbNWnI",
    "outputId": "819c1a1a-63ec-4303-a373-be3d1ce84726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 12,582,912\n",
      "Total Parameters: 3,833,662,464\n",
      "Percentage Trainable: 0.33%\n"
     ]
    }
   ],
   "source": [
    "trainable_params, total_params = model.get_nb_trainable_parameters()\n",
    "percentage = (trainable_params / total_params) * 100\n",
    "\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Percentage Trainable: {percentage:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
