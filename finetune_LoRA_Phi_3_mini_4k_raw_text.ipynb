{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "sQHHSSqt-Jl4"
   },
   "outputs": [],
   "source": [
    "!pip install datasets bitsandbytes trl huggingface-hub accelerate safetensors pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xaaffU0cCSWL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "843fb1086235418ebf18be74dc637c8c",
      "5442800afad44bdca30b6acddbf6283f",
      "f39e2e54564b4eddb45ba4515ae22677",
      "9a8183fe0b4d4192b1d66cfd3086faaa",
      "c335d86edd7346c9bff64b3f7cb60287",
      "4782695a38964f48a5e883f8e4a153d0",
      "8e9de6fecb704e269ccc7adb47c97d2e",
      "41fee8f566fd439f96d3a0038f0fcd4f",
      "b11df7d2879b43e5a3de576ef2e1a9a4",
      "940c9b63f6284f9fbb571f7cdc167105",
      "3eed30733988402da70026db1f7758d0",
      "cfe285a20ade43cea2fceec78743cde3",
      "eb8fba706c1f4271ad51dd2e6aac20d9",
      "4ff95435df1d43d08582a71a7f4b3c27",
      "e4f95f8544874fb6b5238422ac3eb483",
      "a1284decd866422aafb63c31c8f29279",
      "252de24e2afd4f20aad7bb7fdf9e1f59",
      "a85bd1d61d514e738545f3367413d2bb",
      "12b7feb9daff4889b4e5f86c7c5e911d",
      "48432d80ad2644ae8e00462d8e6dbe67",
      "9bd1b06ae32443098199ba0c428fa0ec",
      "05e73742a15a4046a34e2fd61ba15141",
      "2c3084fdc2e243338f62588794583913",
      "9a2d0ea8296d4c928867c27305f65660",
      "dd33ac2cfd344fe085c747be2135b193",
      "f3f7f92ca4ee4315be7d55c724ea7abb",
      "53d7d64f07bb41c59f943f0f42a79f93",
      "a431887c1a9b45fe912d8a4431ce8030",
      "8b31df87ab564c42bc89ed6bb2af4891",
      "9a4c79cba12f4f0793eeb2f99a55275e",
      "404903194b72464a9f345d66204272dd",
      "8e8954d798a44296a4773556cf4fc697",
      "1b251f47a7f7467c89b19d4321432046",
      "119138b31bac4d14ad9aac000c61dd6f",
      "da8cc4de076b45d7a1079fd33696f71e",
      "1a450021f4d7433da6eb2bc8dc9ff58f",
      "dd29c219ea4c440c93070e47c0fe1175",
      "12e25ffe5eae440e806c0a159867ab20",
      "62a996c32d4b4b3cb58020481185cccc",
      "da872f6ec42f441b92be5025b93501b0",
      "273a0a82cd274de984e244d6ce764be9",
      "cc872a1665764203a8e857bd1b5b05b9",
      "55a9f29832a54cf2b46ee685672c26bf",
      "d568fb0e9f2248388be081c75e190759",
      "8b2a42939181447e91891a5d1482c255",
      "0742f6691a954500b85359d939c00a1f",
      "aff4455649044a9cbdb46cf36b93e2b5",
      "ba779948833c4126af7470561ca47ca6",
      "ca2802ae883e432a80940c5aede817e3",
      "00945be6ffb2416ab8b14c986a2df771",
      "614bb3c7795d45a7a1e97d82e3b5f194",
      "15b3a8dfc5ad42d293ac084701c95f8e",
      "74b2c9ec6bfd425f85538a62aef0b35b",
      "10634881ba8b49e9827ea989ec73282a",
      "43a74709b60548f6887de23b38f95f16",
      "b61ce6bb0b444129b1b4d81b2d760123",
      "50a366941d564349a8842c5bfbbf4fa9",
      "3c0846448944400584b355a413f4d0b9",
      "9fb8559569ad4d7787384e5466f94600",
      "1c4c9fb481574fd6a8817b63f7b9d09a",
      "65369e55f7fc45b2b4328b33c618368a",
      "27d69e20170049ddb28e77c9be179b03",
      "df1a4c55115643fd93db0143da84d025",
      "df94ce42341e492aa50cb866630f9f99",
      "4c926f4b4e0e4fb5b78591e1f9474fcd",
      "6d90542ae4694eb8a03c334d138838e1",
      "4ecd93dbb3e4498298a6655861c761f5",
      "f2e166b62a0d4790b69bfc25e5e29763",
      "9d6f81da49c84e2cbc9c9b8708a22ab0",
      "cd154f3abc4745f8a88d082f23e94866",
      "9d818098d90a41508b3fb086ce763f91",
      "5d78d5c6fca84e91958205c1d6dc42b5",
      "5697c4d98b4f40c2b8dc259905fd1899",
      "5c0c434ff52c4005adbf800c125cd3d0",
      "9998b8e7d69b4ae3ade6eca8564715e2",
      "f206725a637c4e2f84a8709c3cc8c050",
      "f4ad4558fbca4d0b9675b0769158e69c"
     ]
    },
    "id": "XB_JtzX0DH1m",
    "outputId": "f66dffd0-6193-47c1-888e-0245f2c3c902"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843fb1086235418ebf18be74dc637c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe285a20ade43cea2fceec78743cde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3084fdc2e243338f62588794583913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119138b31bac4d14ad9aac000c61dd6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2a42939181447e91891a5d1482c255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61ce6bb0b444129b1b4d81b2d760123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecd93dbb3e4498298a6655861c761f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type= \"nf4\",\n",
    "    bnb_4bit_compute_dtype= torch.float32,\n",
    "    bnb_4bit_use_double_quant= True\n",
    "    )\n",
    "repo = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(repo, quantization_config= bnb_config, device_map= \"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404,
     "referenced_widgets": [
      "6f328f1e805449ee8aa63282df93d482",
      "0c85b3f702004440a421c4f67a4ca237",
      "df9a74c2acc14a40b8cfe8bed7009bd7",
      "db49e3d01e1741c8bc55e57c42c0f24a",
      "8842adb0d57f493caaf42a17ba27e596",
      "65ca5dd5294c4308b10e0e1efb2fdc2b",
      "ea4b49ff735f4055be8c24fb2ccdd8e6",
      "7ee8c51ea6f746859d0ee258b21535d8",
      "1e6faca447434d00b29b78b73bb21e78",
      "295563ece6a94e758d20f942d76b600f",
      "4631897f39994eac86da61a10d233f1c",
      "ceb7e7d942434603baf5561c64ed8c1a",
      "a8d7da6743de42098ea1511a02b14e5a",
      "b42ee9b551064407a6505fe22e22f306",
      "e8ef9017892c49cda1fb81c9bc8068f6",
      "51083ac33e0f4ee7a1b35df7b35e1798",
      "bed5aa7765714923ab7dde7b8fd16bc4",
      "bcb079167a1949c3ac5fda9208077e35",
      "35dc7f78cbee4057ab6a97889c1e435d",
      "8a2f8eee538547c8b7e673c558b35c91",
      "2b29a2f2c0b34629b8af0d0191356950",
      "7528a71900424a8abe2ff229904677b5",
      "94343f5f80f8432c93500b52ce54f8c6",
      "05289a93b07a4d00bbc61e578aec735a",
      "e26a2d11ac8649f994c008d1bd488a03",
      "c20aab3015554670a31593464e938967",
      "e16e66546aff472ab4b3a38a54e51b64",
      "07c5b304ae9243828910c0dac5b5b931",
      "f124826ed3d04989bf2f44f9a4eef2fd",
      "ecb428438801443b8043ce570c0bd6f9",
      "ca05fc0029fa4242825b60e36575dba8",
      "469dd301fea54976acd39acb61bd8936",
      "c955ab4a17144281a4802c0e703effc0",
      "b3b332d5c4be489d859e3c89f5cff884",
      "ca67df6d67504506bdf6b118660e93c8",
      "a11928eb8bce431d94125f8d6a8dc63e",
      "17f30154fc7149bcb08a92e2481e0619",
      "f25ee0daa95741b8be2e39764df5d1cb",
      "90b2e233cc9b48e28de1f0e3ab04bfcc",
      "d28e1f702d81488280db9557c5a40e77",
      "384fc791dcb34587bf5d77b85e8f954f",
      "dc6027e3fa0c4fa4b3779a546c79109f",
      "19645b8be7a74569a6eb9105a0ba0a43",
      "25c478b133d54bb4b96e939f77d38007",
      "e05be2313a29496eb32170d2212d43df",
      "a18127c577a94795ac0c344e5093894e",
      "74e43ee482394ba68d78efd9fe30e5f1",
      "0f26f375995544a2821f0ad42d77949a",
      "7c761aefc78d46beaee567f44442a38c",
      "ecbdc09eb9cd46779dcebc11cb906e42",
      "26f5dfe7e3574cbbbdf5efd9f97fe92e",
      "551fc560c13c43f8b2fae90e92183f79",
      "475f1cc8e0514e56abaed9a063a1ca5c",
      "77a080b7f0bd49e6b1ce6c4b55f4315f",
      "78dc21361ebf47d7a424d39db807a115",
      "3f8050e3d35e41f689b3f688f04d7eac",
      "af8669fbefb6424aa25c3646c853c07f",
      "0f93c93d47b14402887bb730f6619979",
      "8fab82060d294880b3e8ddbc558029df",
      "b9afe560182c4d94831d0c352d35520b",
      "de75e6c0cb1647588d05a43d35102090",
      "fc49a7824b11474aa423b31edcd7002e",
      "372bd5a1e55943dab9344f67f3f48509",
      "26b6fe5a13ec4626b8ea2aed8f7d911f",
      "61d75957d8ee4c3eb93037c62db5e184",
      "ad6ad18a6ebe4b99ab9428f69d253e8c",
      "a21df4cf8f86460191339087d5375382",
      "699d273a8937453e8dab709c8cd9f9c8",
      "32ea5a1170d94f63a8965f9295099722",
      "baa503b94fe44159b530a0d70d25dca4",
      "8492ee04cc604642ab6fb1f227798a58",
      "62993273bacc4981bb839a812e3c8cae",
      "17f987b6ab744c918eb9b80bdf22d2ab",
      "92a0ca0d7bdd49e1a6290d74e9e184bb",
      "682edcc5b3b44b16a8752cfcccdaeb0f",
      "03aef82a4f284668ad97c25a5b096753",
      "ad86887d4f46422898c88c20acbefa07"
     ]
    },
    "collapsed": true,
    "id": "dnqd-dgmFvKf",
    "outputId": "d4ec5425-62a8-4a4b-bc7d-28e7b7054874"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f328f1e805449ee8aa63282df93d482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb7e7d942434603baf5561c64ed8c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94343f5f80f8432c93500b52ce54f8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b332d5c4be489d859e3c89f5cff884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05be2313a29496eb32170d2212d43df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8050e3d35e41f689b3f688f04d7eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21df4cf8f86460191339087d5375382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# torch.random.manual_seed(0)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "#     device_map=\"cuda\",\n",
    "#     torch_dtype=\"auto\",\n",
    "#     trust_remote_code=True,\n",
    "# )\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"},\n",
    "#     {\"role\": \"assistant\", \"content\": \"Sure! Here are some ways to eat bananas and dragonfruits together: 1. Banana and dragonfruit smoothie: Blend bananas and dragonfruits together with some milk and honey. 2. Banana and dragonfruit salad: Mix sliced bananas and dragonfruits together with some lemon juice and honey.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"What about solving an 2x + 3 = 7 equation?\"},\n",
    "# ]\n",
    "\n",
    "# pipe = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "\n",
    "# generation_args = {\n",
    "#     \"max_new_tokens\": 500,\n",
    "#     \"return_full_text\": False,\n",
    "#     \"temperature\": 0.0,\n",
    "#     \"do_sample\": False,\n",
    "# }\n",
    "\n",
    "# output = pipe(messages, **generation_args)\n",
    "# print(output[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee3M9pnjEUaW",
    "outputId": "fedeb1a0-14b2-4749-fe19-52f2fcf5332b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2104.1310424804688\n"
     ]
    }
   ],
   "source": [
    "print(model.get_memory_footprint()/1024/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRZA6aC4HXk4",
    "outputId": "bd6c03ee-cec9-45e3-8c9a-18e39246ee4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phi3ForCausalLM(\n",
       "  (model): Phi3Model(\n",
       "    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x Phi3DecoderLayer(\n",
       "        (self_attn): Phi3Attention(\n",
       "          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "          (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n",
       "        )\n",
       "        (mlp): Phi3MLP(\n",
       "          (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "          (activation_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): Phi3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XPoMdAY4JDbP",
    "outputId": "ca5d5630-6d69-4119-a68e-d94f9359ed9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Phi3ForCausalLM(\n",
       "      (model): Phi3Model(\n",
       "        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x Phi3DecoderLayer(\n",
       "            (self_attn): Phi3Attention(\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (qkv_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=9216, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9216, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): Phi3MLP(\n",
       "              (gate_up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=16384, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=16384, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (activation_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): Phi3RotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "config = LoraConfig(\n",
    "    r = 8, #. rank of LoRA - [4-16]\n",
    "    bias = \"none\", # [\"all\", \"lora_only\"] - for train bias term\n",
    "    lora_alpha = 16, # scalling factor\n",
    "    lora_dropout = 0.05, # prevent overfit- used for regularisation\n",
    "    target_modules = [\"query_key_value\", \"o_proj\", \"qkv_proj\", \"gate_up_proj\", \"down_proj\"],\n",
    "    task_type = \"CAUSAL_LM\"\n",
    "\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_Lxz8fPMuhX",
    "outputId": "2e3a63a6-e7e4-4756-e323-c0fa641b60bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2528.2619018554688\n"
     ]
    }
   ],
   "source": [
    "print(model.get_memory_footprint()/1024/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wDx5hjxXM6ZS",
    "outputId": "b324c2e1-e64e-48d8-e142-6dbc0b9efd34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method PeftModel.get_base_model of PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): Phi3ForCausalLM(\n",
      "      (model): Phi3Model(\n",
      "        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x Phi3DecoderLayer(\n",
      "            (self_attn): Phi3Attention(\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (qkv_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3072, out_features=9216, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=9216, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (mlp): Phi3MLP(\n",
      "              (gate_up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3072, out_features=16384, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=16384, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=8192, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (activation_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
      "            (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
      "            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
      "        (rotary_emb): Phi3RotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
      "    )\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.get_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1xiTbhpNGYd",
    "outputId": "6c559720-5f5d-43c3-9bc7-88941a2e0009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2651.074752\n"
     ]
    }
   ],
   "source": [
    "print(model.get_memory_footprint()/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnvrkrmbNWnI",
    "outputId": "0121ab3b-72e8-419b-9d76-42ae1eefffcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 12,582,912\n",
      "Total Parameters: 3,833,662,464\n",
      "Percentage Trainable: 0.33%\n"
     ]
    }
   ],
   "source": [
    "trainable_params, total_params = model.get_nb_trainable_parameters()\n",
    "percentage = (trainable_params / total_params) * 100\n",
    "\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Percentage Trainable: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "jPO5lDk2O03-",
    "outputId": "f36fb270-c44c-47b3-c766-1eee412d0c61"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"{% for message in messages %}{% if message['role'] == 'system' %}{{'<|system|>\\n' + message['content'] + '<|end|>\\n'}}{% elif message['role'] == 'user' %}{{'<|user|>\\n' + message['content'] + '<|end|>\\n'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>\\n' + message['content'] + '<|end|>\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>\\n' }}{% else %}{{ eos_token }}{% endif %}\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(repo)\n",
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "6f_nb1ZwNnT_"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import re\n",
    "\n",
    "# Sample raw text\n",
    "with open(\"/content/3MINDIA_2021.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "# Optionally clean and normalize\n",
    "raw_text = re.sub(r\"\\s+\", \" \", raw_text).strip()\n",
    "\n",
    "# Split into chunks (e.g., every ~1000 characters or tokens)\n",
    "chunk_size = 1000\n",
    "text_chunks = [raw_text[i:i+chunk_size] for i in range(0, len(raw_text), chunk_size)]\n",
    "\n",
    "# Wrap into a Hugging Face dataset\n",
    "dataset = Dataset.from_dict({\"text\": text_chunks})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "lGBk8FI8Nrc0"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cT5Ftxn4OcrE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "867da6c8f8414ba19230777541c21dea",
      "8a8a0d7970a645d383d9f414e2972116",
      "73045718a9ab491b8a387ab52ea98488",
      "3fb9afc404704862a3b8bb7addb691ba",
      "a2f7de3586b24c519a6793e444200750",
      "c91897fb24944d869a8fa55de6cc8de7",
      "b9d821eaa0a64c6bae61435e09e78a64",
      "e2025ab44c9d43b8b737ae3e8fc217a9",
      "a4c7f6a6e94e43f99a882de9615ee8fe",
      "20fb484deaec4717b9b6d42daf9fb495",
      "9f41d94997a24767a5a8c8924264358d"
     ]
    },
    "id": "jYBf0nyzNtdE",
    "outputId": "2876ccc4-430c-4d4b-fafb-21949e37d5b8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867da6c8f8414ba19230777541c21dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/495 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "JCoJxSVRNvvB"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # for causal LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "4lk3Y_JxPaSm"
   },
   "outputs": [],
   "source": [
    "sft_config = SFTConfig(\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant': True},  # <-- fixed here\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    auto_find_batch_size=True,\n",
    "    max_seq_length=64,\n",
    "    packing=True,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=3e-4,\n",
    "    optim='paged_adamw_8bit',\n",
    "    logging_steps=10,\n",
    "    logging_dir=\"/content/drive/MyDrive/phi3-mini-sarcasm/logs\",\n",
    "    output_dir=\"/content/drive/MyDrive/phi3-mini-sarcasm/adapter\",\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222,
     "referenced_widgets": [
      "552d6edf66584c98bd26565d2da5dfd2",
      "c4c2ff47e3a94a5aa9297c0264fb1297",
      "bbe8985924204817a1b0dbb8340a91c0",
      "26ee3e878c744bdaabe1efe73f1caa5e",
      "752051986a434d8ab098270454a62583",
      "61dcb468e49e4e9486a5161c84eeaa00",
      "b0f072e2fac74cfbbd9e5aa9723a87d6",
      "67d0bb371e8e4050a6d30ae0e94d9c40",
      "ed6107cfc7d04f63b2a366efe12399bc",
      "89ef58aeebee40a39050ab28a5e1ee88",
      "6df419d0af2445d68d3f343fd2e83065",
      "f4a38b853d1a4ac3ac368a48234ebf27",
      "1dc99db7af2240dbbaf3ac1564877fee",
      "205cb02b3ee74506be0990c18aca336d",
      "55dfd32c8ee04aa5b5738a974d519035",
      "2c0f0686b0ae4e9c95b0e2958de6ac4d",
      "4c9db39841ad484396bba8768b0a951a",
      "ee6958605034439eae3f1c780e3f1fd0",
      "70749b7cda884612ad001698c129087a",
      "9b9d23b3a2b4403d874bf9c45cda6b74",
      "df6d105421bc4315bf0295ce898c3cb3",
      "aa77b730209f4304837ef84b35ea1a20",
      "b26e9e91fa7c43caa4042978c66d21e3",
      "8b8b547113504e2fb0d08442094a7e88",
      "94ade343d2b44051a69cb160a4d8e474",
      "d7e08941ec604ffeb1efd56f2d0a2c90",
      "e4877eb84a3b4e3289b53038d9bef414",
      "aa256e6d5d704ca78949a675777d7dfe",
      "7a313cdcc827469389664d06d628744d",
      "21194faf35ff403588df3b489ce7c883",
      "921626777097443985e951ea11aa9f23",
      "edd21d3d733d4c4387412438aa3fd035",
      "eed569c0a0424963ae0fb7ecf40fb124"
     ]
    },
    "id": "q_Wc7PRhPgfX",
    "outputId": "7ab10737-92c9-4d24-d7d6-661ebee5bdf5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:412: UserWarning: Padding-free training is enabled, but the attention implementation is not set to 'flash_attention_2'. Padding-free training flattens batches into a single sequence, and 'flash_attention_2' is the only known attention mechanism that reliably supports this. Using other implementations may lead to unexpected behavior. To ensure compatibility, set `attn_implementation='flash_attention_2'` in the model configuration, or verify that your attention mechanism can handle flattened sequences.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:458: UserWarning: You are using packing, but the attention implementation is not set to 'flash_attention_2'. Packing flattens batches into a single sequence, and 'flash_attention_2' is the only known attention mechanism that reliably supports this. Using other implementations may lead to cross-contamination between batches. To avoid this, either disable packing by setting `packing=False`, or set `attn_implementation='flash_attention_2'` in the model configuration.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552d6edf66584c98bd26565d2da5dfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/495 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a38b853d1a4ac3ac368a48234ebf27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/495 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26e9e91fa7c43caa4042978c66d21e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Packing train dataset:   0%|          | 0/495 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer=SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    processing_class=tokenizer,\n",
    "    args=sft_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "gojoSi8NPpmO"
   },
   "outputs": [],
   "source": [
    "dl=trainer.get_train_dataloader()\n",
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISDUea57PtVz",
    "outputId": "aa7ba0d0-1ebc-43ef-8b06-9ebe035c2d07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  382, 15082,   382,  ...,   571, 16750, 21764], device='cuda:0'),\n",
       " tensor([  382, 15082,   382,  ...,   571, 16750, 21764], device='cuda:0'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'][0], batch['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jBW87k_BPxU4",
    "outputId": "eb45b6f7-0e10-4a56-cda1-d76e11310c31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='310' max='310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [310/310 08:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.793600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.476000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.512600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.236500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.929100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.597900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.628200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.489000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.204600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.970700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.879400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.619200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.586500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.215100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.222200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.885800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.923500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.899100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.670100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.680300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.673800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.515200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.553200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.545800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.450100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.434600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=310, training_loss=1.6650743038423599, metrics={'train_runtime': 507.7168, 'train_samples_per_second': 9.75, 'train_steps_per_second': 0.611, 'total_flos': 7099795655884800.0, 'train_loss': 1.6650743038423599})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Dl4oTN83Nz42"
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     train_dataset=tokenized_dataset,\n",
    "#     eval_dataset=tokenized_dataset,  # or split if needed\n",
    "#     args=training_args,\n",
    "#     data_collator=data_collator,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "TiU6Wo-sktLZ"
   },
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"sweatSmile/sarcastic-dataset\", split=\"train\")\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8sLyAYo2YS9",
    "outputId": "64375209-1b73-4241-db26-b9e889f4616d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '3 M India Limited WeWork Prestige Central 3rd floor 36 Infantry Road Tasker Town Bangalore 560001 India Office 80 22231414 Registered Office Plot 51 Electronics City Hosur Road Bangalore 560 100 India Office 80 45594300 CIN L31300KA1987PLC013543 investor helpdesk PAN AAACB5724H GSTIN 29AAACB5724H1ZQ July 27 2021 Corporate Relationship Department Bombay Stock Exchange Limited 1st Floor New Trading Ring Rotunda Building Towers Dalal Street Fort Mumbai 400 001 Scrip Code 523395 Secretary National Stock Exchange India Limited Exchange Plaza Bandra Kurla Complex Bandra E Mumbai 400 051 Scrip Code 3MINDIA Dear Sir Sub 34th Annual General Meeting Notice cum Annual Report 2020 21 Ref Reg read para Schedule III SEBI LODR Regulations 2015 continuation letter dated 28 2021 find attached Notice cum complete set Annual Report 2020 21 34th Annual General Meeting AGM Company held IST Thursday August 26 2021 Video Conferencing Audio Visual Means electronic copies Notice AGM Annual Report 2020 21 sent '}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHOCBb0o2a-Q",
    "outputId": "244d098f-d901-4522-9ca9-f4fda4bc24e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion'],\n",
       "    num_rows: 720\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = dataset.rename_column(\"sentence\", \"prompt\")\n",
    "# dataset = dataset.rename_column(\"translation_extra\", \"completion\")\n",
    "# dataset = dataset.remove_columns([\"translation\"])\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5TOy0BZ3MAG",
    "outputId": "3b7d003c-efb9-494b-eadd-776534feed72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '3 M India Limited WeWork Prestige Central 3rd floor 36 Infantry Road Tasker Town Bangalore 560001 India Office 80 22231414 Registered Office Plot 51 Electronics City Hosur Road Bangalore 560 100 India Office 80 45594300 CIN L31300KA1987PLC013543 investor helpdesk PAN AAACB5724H GSTIN 29AAACB5724H1ZQ July 27 2021 Corporate Relationship Department Bombay Stock Exchange Limited 1st Floor New Trading Ring Rotunda Building Towers Dalal Street Fort Mumbai 400 001 Scrip Code 523395 Secretary National Stock Exchange India Limited Exchange Plaza Bandra Kurla Complex Bandra E Mumbai 400 051 Scrip Code 3MINDIA Dear Sir Sub 34th Annual General Meeting Notice cum Annual Report 2020 21 Ref Reg read para Schedule III SEBI LODR Regulations 2015 continuation letter dated 28 2021 find attached Notice cum complete set Annual Report 2020 21 34th Annual General Meeting AGM Company held IST Thursday August 26 2021 Video Conferencing Audio Visual Means electronic copies Notice AGM Annual Report 2020 21 sent '}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4qTqMoK3QS3",
    "outputId": "84905425-5271-427c-e4db-99bc5bea33c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': {'text': '3 M India Limited WeWork Prestige Central 3rd floor 36 Infantry Road Tasker Town Bangalore 560001 India Office 80 22231414 Registered Office Plot 51 Electronics City Hosur Road Bangalore 560 100 India Office 80 45594300 CIN L31300KA1987PLC013543 investor helpdesk PAN AAACB5724H GSTIN 29AAACB5724H1ZQ July 27 2021 Corporate Relationship Department Bombay Stock Exchange Limited 1st Floor New Trading Ring Rotunda Building Towers Dalal Street Fort Mumbai 400 001 Scrip Code 523395 Secretary National Stock Exchange India Limited Exchange Plaza Bandra Kurla Complex Bandra E Mumbai 400 051 Scrip Code 3MINDIA Dear Sir Sub 34th Annual General Meeting Notice cum Annual Report 2020 21 Ref Reg read para Schedule III SEBI LODR Regulations 2015 continuation letter dated 28 2021 find attached Notice cum complete set Annual Report 2020 21 34th Annual General Meeting AGM Company held IST Thursday August 26 2021 Video Conferencing Audio Visual Means electronic copies Notice AGM Annual Report 2020 21 sent '}},\n",
       " {'role': 'assistant',\n",
       "  'content': {'text': '3 M India Limited WeWork Prestige Central 3rd floor 36 Infantry Road Tasker Town Bangalore 560001 India Office 80 22231414 Registered Office Plot 51 Electronics City Hosur Road Bangalore 560 100 India Office 80 45594300 CIN L31300KA1987PLC013543 investor helpdesk PAN AAACB5724H GSTIN 29AAACB5724H1ZQ July 27 2021 Corporate Relationship Department Bombay Stock Exchange Limited 1st Floor New Trading Ring Rotunda Building Towers Dalal Street Fort Mumbai 400 001 Scrip Code 523395 Secretary National Stock Exchange India Limited Exchange Plaza Bandra Kurla Complex Bandra E Mumbai 400 051 Scrip Code 3MINDIA Dear Sir Sub 34th Annual General Meeting Notice cum Annual Report 2020 21 Ref Reg read para Schedule III SEBI LODR Regulations 2015 continuation letter dated 28 2021 find attached Notice cum complete set Annual Report 2020 21 34th Annual General Meeting AGM Company held IST Thursday August 26 2021 Video Conferencing Audio Visual Means electronic copies Notice AGM Annual Report 2020 21 sent '}}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": dataset[0]},\n",
    "    {\"role\": \"assistant\", \"content\": dataset[0]}\n",
    "]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231,
     "referenced_widgets": [
      "36b70d1b09f54b108414c6bbb9e3b4a9",
      "69e8aed4633a490589eac84695895976",
      "e7b98339fd1249d5b89411ba49602d28",
      "e9599a8010bd416e97a0735a98551f46",
      "5491a44e54f94537b07b6e7f2759b6a5",
      "5014f34aadd1428d9a82744905038f6f",
      "95284a1b86774792ab9c70154eb40b5e",
      "37ce53a05b9d4b7bb97fe4e0a4e6c704",
      "8875e185450a4fdeab82a4c9f5af81d8",
      "78a200df0eb443d1ac9594d0efa3d9c2",
      "53b1c253c8ce4c1386edd5032ab279cc",
      "1e1a449b996f46a8bc797be3ff9a814a",
      "54b7994e789a48e591e63a0ed0ebb599",
      "9cbb8a2c55294e4cbdae9ef30b329911",
      "709fbb4b1724453b90b849766677f6ed",
      "f6bb0b06098d4133a6de3479be7b6285",
      "0bfe3d00922148dfa3d0588d3d9a59a3",
      "b5945a2516834066a0c2a202694f8381",
      "da7843b88abf405e9bb89be1ad907724",
      "9d1fb7b65ba74c8ab6624d54d5030cc3",
      "adac08abeb304069b06421ed47c78a38",
      "7f79c1697612492db9a17907caac4ea5",
      "21fe00331031418b845e080798d2d174",
      "03ce1f654ef94974b717181d5553f9c0",
      "c042e2f054514912b88f7c0bce6ddbcc",
      "bd46f3171153478694ba854edddf64f8",
      "348d1c2937314a5f95e42591b034f487",
      "c3e463260ea148bfac4b9a61557bf297",
      "dd26e852540449648e389db5d63feb93",
      "fdba177a247e4cc39ad6492ddd83c310",
      "a829f4d8b09f4b629d27c0f95f385550",
      "fb313c790aaa47a9915bee0199ed97ac",
      "775fde75fb51441cb8a9496212084e4d",
      "4c2eebdc273d474c8fa8c79568b1edf7",
      "c7deb684523b48baaf817d62d6653110",
      "3d6cabd7dc61438f92acde4196176910",
      "8762289aebe341dc85236defa187ff80",
      "98ac8b58b3894acf8dde90c3d80439a2",
      "771588c71e9443eb8f01d0e017d89a54",
      "4381f1c4dac74706b417b9c5f64fa842",
      "b5a4f0ce760943678e3e8f24917365ac",
      "1154430265944b0896d4b608abb04569",
      "c44be78fa4df40a0a636d2806811e734",
      "d90d6f68e5f34449960ca4c7f3d9df9b",
      "9f1bd0bfd9734fbeb3d5f9ba0efe845c",
      "ec6b18c156184aaea34e8273d7cb7552",
      "e3b62f1dc947416cae5ff905f95cc2d4",
      "66a9838841b54a068d4373a0a1d5fd03",
      "25511d48978a46308f0489cbb7a8eccc",
      "21d53ae0e8d2401299ab04b61b1c13b1",
      "b37174921f354b80b855d9120d025721",
      "50035ac3f9a74ca2965e18cc6087c32c",
      "833592e7c45a4e3db6ae2e947be8723c",
      "88820072fa39409b9a8ad343010ac6c4",
      "0c536e0543604fd7811d7dc2c250804b"
     ]
    },
    "id": "1hcb7yGU3kBJ",
    "outputId": "c6b23aed-d7e7-4df2-babf-8de35de3a0b8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b70d1b09f54b108414c6bbb9e3b4a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1a449b996f46a8bc797be3ff9a814a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21fe00331031418b845e080798d2d174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2eebdc273d474c8fa8c79568b1edf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1bd0bfd9734fbeb3d5f9ba0efe845c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"{% for message in messages %}{% if message['role'] == 'system' %}{{'<|system|>\\n' + message['content'] + '<|end|>\\n'}}{% elif message['role'] == 'user' %}{{'<|user|>\\n' + message['content'] + '<|end|>\\n'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>\\n' + message['content'] + '<|end|>\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>\\n' }}{% else %}{{ eos_token }}{% endif %}\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(repo)\n",
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u06m-jee3-OE",
    "outputId": "ba26c905-39ef-4964-a21e-c416c95eedbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "The birch canoe slid on the smooth planks.<|end|>\n",
      "<|assistant|>\n",
      "Oh, wow, a birch canoe slid on smooth planks? Who would have thought that would happen? Next, you'll tell me water's wet and the sky is blue!<|end|>\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.apply_chat_template(messages, tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "37YSxIj34ET7"
   },
   "outputs": [],
   "source": [
    "sft_config = SFTConfig(\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant': True},  # <-- fixed here\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    auto_find_batch_size=True,\n",
    "    max_seq_length=64,\n",
    "    packing=True,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=3e-4,\n",
    "    optim='paged_adamw_8bit',\n",
    "    logging_steps=10,\n",
    "    logging_dir=\"/content/drive/MyDrive/phi3-mini-sarcasm/logs\",\n",
    "    output_dir=\"/content/drive/MyDrive/phi3-mini-sarcasm/adapter\",\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222,
     "referenced_widgets": [
      "fddccbe6a8764a7da55e37ffba23e327",
      "939c6434687d4907979056e928355fac",
      "888ac7ab861848c19b816bb7d8e721a4",
      "0eb1ada3349a4d37ad248ee37b791617",
      "73db8dd78d1b4b48bb3f5d5d104873d1",
      "e42b6f8896064e19a0b36fc0d55c7591",
      "cc1b2303e3ba4e12b9e87c74e46da9f6",
      "6790dd955a854cb7a184f70602b2b626",
      "9f9a627b221b493ba0dd18ee0446dca9",
      "eb30d84f348541f4965d959136a28802",
      "a0ced5da078c40fa80256d1287fb8da4",
      "b20a21b29b2e4deebe37135cb4ca379a",
      "38ee968d27314ddaa813cd4cd53bb3c3",
      "3ab3559d49664e5e88f6f7605f3a547c",
      "335d8f87b2e94ffa8a797954c808a3ad",
      "3c5ed323dc3349359e27e7548a668d95",
      "ad003be428c54ef3a669ecdaeae8489d",
      "7ab10c70852f431ca98ece357e2d3573",
      "616f6c29f6c346f386673129873c9171",
      "cf335c8deedd4e4c9f544f77243625b6",
      "cdd011a20f5e45f1bdac59fdb5b5907e",
      "57ef6ac75f0b4a5186dc673d17ee30c5",
      "c086a90257b74356befe7a281f0be82f",
      "b8a0ee2078984f949351996fc8b3144b",
      "7b51d59355eb47359ba620cf730e3a9e",
      "69fd55655360463eb84db2052542d793",
      "6042a42577a346bc86359f86c04d1b50",
      "f65fb4c331d1464d8947500846d76f1a",
      "6fba95cff64642a290df4a35a715c772",
      "6dcfecfe0e89476587192310663c88aa",
      "dcce1f38e8544732bba463ae0d2389dc",
      "f2efc085834248b9a57d37876e868f17",
      "9aa45c1bf720411ca557fd543d83d71f"
     ]
    },
    "id": "xlHPy5Vt6S9T",
    "outputId": "9ccfa3ae-feef-44e1-b051-00162244a371"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:412: UserWarning: Padding-free training is enabled, but the attention implementation is not set to 'flash_attention_2'. Padding-free training flattens batches into a single sequence, and 'flash_attention_2' is the only known attention mechanism that reliably supports this. Using other implementations may lead to unexpected behavior. To ensure compatibility, set `attn_implementation='flash_attention_2'` in the model configuration, or verify that your attention mechanism can handle flattened sequences.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:458: UserWarning: You are using packing, but the attention implementation is not set to 'flash_attention_2'. Packing flattens batches into a single sequence, and 'flash_attention_2' is the only known attention mechanism that reliably supports this. Using other implementations may lead to cross-contamination between batches. To avoid this, either disable packing by setting `packing=False`, or set `attn_implementation='flash_attention_2'` in the model configuration.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddccbe6a8764a7da55e37ffba23e327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/495 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20a21b29b2e4deebe37135cb4ca379a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/495 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c086a90257b74356befe7a281f0be82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Packing train dataset:   0%|          | 0/495 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer=SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    processing_class=tokenizer,\n",
    "    args=sft_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "6iHRLxZS6xRS"
   },
   "outputs": [],
   "source": [
    "dl=trainer.get_train_dataloader()\n",
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lS8kjrO7Cb7",
    "outputId": "6755e083-35be-4a25-c841-68998c71e243"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  382, 15082,   382,  ...,   571, 16750, 21764], device='cuda:0'),\n",
       " tensor([  382, 15082,   382,  ...,   571, 16750, 21764], device='cuda:0'))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'][0], batch['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Amt9AU5i7K8z",
    "outputId": "31a29436-9e82-445f-aea9-df7742594adb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [450/450 10:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.339000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.759700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.802800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.688300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.539300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.510300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.522200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.512800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.214100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.112200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.113400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.166600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.922100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.718400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.710500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.729300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.736300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.450500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.434200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.445200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.471300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.382300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.289500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.308600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.322700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.232200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.238700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.228700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.251600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.227300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.198600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.170500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.170200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.180900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.172900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.155800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.168600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.161700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=450, training_loss=0.6869243285391066, metrics={'train_runtime': 608.5035, 'train_samples_per_second': 11.717, 'train_steps_per_second': 0.74, 'total_flos': 7742318198353920.0, 'train_loss': 0.6869243285391066})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lnPj_ooF-qV0"
   },
   "outputs": [],
   "source": [
    "def gen_prompt(tokenizer, sentence):\n",
    "  converted_sample = [{\"role\": \"user\", \"content\": sentence}]\n",
    "  prompt = tokenizer.apply_chat_template(converted_sample, tokenize=False, add_generation_prompt=True)\n",
    "  return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "IwgIKkIgBKuM",
    "outputId": "d1fa65a3-81a3-4c77-ddc7-14d7a7ed2127"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<|user|>\\nThe birch canoe slid on the smooth planks.<|end|>\\n<|assistant|>\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'The birch canoe slid on the smooth planks.'\n",
    "prompt = gen_prompt(tokenizer, sentence)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9OryiZcXBfvU"
   },
   "outputs": [],
   "source": [
    "def generate(model, tokenizer, prompt, max_new_tokens=64, skip_special_tokens=True):\n",
    "  tokenized_input = tokenizer(prompt,add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n",
    "  model.eval()\n",
    "  generation_output = model.generate(**tokenized_input, max_new_tokens=max_new_tokens, eos_token_id=tokenizer.eos_token_id)\n",
    "  output = tokenizer.batch_decode(generation_output, skip_special_tokens=skip_special_tokens)[0]\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cf-M2TAkJOwj",
    "outputId": "122bda19-eb31-4924-df52-3bf9c708af2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The birch canoe slid on the smooth planks. The birch canoe glided effortlessly across the calm, glassy surface of the lake, propelled by the skilled paddles of its occupants. The smooth planks of the canoe, crafted from the sturdy and lightweight wood of the birch tree, allowed for a swift\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, tokenizer, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "-HQwru1OMEuj",
    "outputId": "4a508380-2361-4aaf-a426-2d42ac64cbdf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<|user|>\\nwhats the 3m csr responsiblity<|end|>\\n<|assistant|>\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'whats the 3m csr responsiblity'\n",
    "prompt = gen_prompt(tokenizer, sentence)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "UmrQF9fvMH28"
   },
   "outputs": [],
   "source": [
    "def generate(model, tokenizer, prompt, max_new_tokens=64, skip_special_tokens=True):\n",
    "  tokenized_input = tokenizer(prompt,add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n",
    "  model.eval()\n",
    "  generation_output = model.generate(**tokenized_input, max_new_tokens=max_new_tokens, eos_token_id=tokenizer.eos_token_id)\n",
    "  output = tokenizer.batch_decode(generation_output, skip_special_tokens=skip_special_tokens)[0]\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SRmcj5miMJhX",
    "outputId": "8c598102-66e8-4c1f-e917-418e9496bb4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whats the 3m csr responsiblity The 3M Company, formerly known as Minnesota Mining and Manufacturing Company, is a multinational conglomerate corporation with a diverse range of products and services. As a global leader in innovation, 3M has a responsibility to various stakeholders, including shareholders,\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, tokenizer, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BxzfDqG2MY_W"
   },
   "outputs": [],
   "source": [
    "trainer.save_model('ak-phi3-mini-sarcasm-adapter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJPBI2RAUOmj"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234,
     "referenced_widgets": [
      "cad2ef13d3e34fd29688aee87a1bd6f8",
      "a3f9b4e6da3a4354b0076f767510bbe2",
      "765062a998ff43c5a6f446786f0fd718",
      "b5adf4e67790434bb612cf4ba31fc804",
      "7407881281ba49a3aa34381d12056f27",
      "1e6f949a83e94669b9440aadbbb55b56",
      "8b6e841e065e4668b49823247607326c",
      "328c2d4f6930438a9fc33a63cd68f98b",
      "03f445e13a894e609471e0e3c080432e",
      "ec2ca9c59df248b38d33df72c8886fd7",
      "e6289e72f0824053a8859650d08d61de",
      "c922f515a278435ba9186a067cfd98f5",
      "4148d3b0da934a0cb091e46b6d764307",
      "685a808f68d24bf19c55cec5260b61ce",
      "9e00c72fa68448b6b8234f21db5c867e",
      "a1d63dbc81e04040a722fa8c0784b8e9",
      "1c3259429e5f49239dd6e55a47234c15",
      "9a5e63553c494d0d8870cba436039d1b",
      "f768045008f24b4ebfaa7097d8e260a1",
      "bb8607753fb44f348783aa0eb2b13822",
      "3209a2ec32db46c4a1430becd1a4fde5",
      "c67d03b7b0a74e04805b9cbf56dbd0a2",
      "edc6f5e820f1442abc2b5ca2c11d06ca",
      "6a02612886c74dd199825066b1daad83",
      "4cfa8a6941da44a0b8df69890ffa007f",
      "51a64f0a2e6a4328888d0f33b03df94a",
      "3f0a856ec1fb4666b0075f41fbf1d16d",
      "89c6f7233a924b088860ec5e9d34b109",
      "2ee5f1a0ea0a42e09aa7aa437bb92122",
      "8a45df3d68ea4c45bab58d3d499b5e77",
      "8548512df2d94558a392276bf73eb7c6",
      "c4e7f78352f84dcdba0321d2f746a254",
      "821de32907c34ebdbf03bdf28b85d5ea",
      "b93b8cca0bdf41af92cc01e5377a9836",
      "56012d81e26c4faa981b4bf823b62a8d",
      "8168285621a442b78c3033dafdca931d",
      "94c9f6d4c28b45c29edee1eca093e010",
      "d9c7319616a64094adbf9206fb5c5c6d",
      "680df85b4a4049ea8760db9e51bff239",
      "34003727aafc47af97f63af71bdae290",
      "71df31addba34d8e9cfda9c16136846b",
      "b3bbf702ecce48d7947191b2cf958504",
      "14d6b9f8293d4bc192ae6329ebbc5cd9",
      "070bedc10c124cd7a6156ba9f407e80b"
     ]
    },
    "id": "l1xW8YTnVVaL",
    "outputId": "b34a2cf8-c504-4a0e-901d-11a403f95bc5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad2ef13d3e34fd29688aee87a1bd6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/50.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c922f515a278435ba9186a067cfd98f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc6f5e820f1442abc2b5ca2c11d06ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93b8cca0bdf41af92cc01e5377a9836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sweatSmile/ak-phi3-mini-sarcasm-adapter/commit/d7dcf765f4bd5b8a570d500681c51dd7626ea28b', commit_message='Upload folder using huggingface_hub', commit_description='', oid='d7dcf765f4bd5b8a570d500681c51dd7626ea28b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sweatSmile/ak-phi3-mini-sarcasm-adapter', endpoint='https://huggingface.co', repo_type='model', repo_id='sweatSmile/ak-phi3-mini-sarcasm-adapter'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi(token=\"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\")  # paste your write-access token here\n",
    "api.upload_folder(\n",
    "    folder_path=\"/content/ak-phi3-mini-sarcasm-adapter\",  # full absolute path\n",
    "    repo_id=\"sweatSmile/ak-phi3-mini-sarcasm-adapter\",\n",
    "    repo_type=\"model\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "Gf-k0T14XOER",
    "outputId": "dbd31d88-aa2b-47ac-c186-a4f0a90b523b"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (ipython-input-59-2104413733.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-59-2104413733.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    readme_content = \"\"\"\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "readme_content = \"\"\"\n",
    "#  ak-phi3-mini-sarcasm-adapter\n",
    "\n",
    "## Model Details\n",
    "\n",
    "**Developed by**: sweatSmile (https://huggingface.co/sweatSmile)\n",
    "**Model type**: PEFT Adapter (LoRA)\n",
    "**Language(s)**: English\n",
    "**License**: Apache 2.0\n",
    "**Fine-tuned from**: `microsoft/phi-3-mini-4k-instruct`\n",
    "**Framework**: PEFT v0.15.2, Transformers\n",
    "**Finetuning Library**: `trl` with `SFTTrainer`\n",
    "\n",
    "## Model Sources\n",
    "\n",
    "- [Repository](https://huggingface.co/sweatSmile/ak-phi3-mini-sarcasm-adapter)\n",
    "\n",
    "## Uses\n",
    "\n",
    "### Direct Use\n",
    "The model is fine-tuned to detect and understand **sarcasm in text**, useful in:\n",
    "- Sentiment analysis\n",
    "- Social media content moderation\n",
    "- Conversational agents\n",
    "\n",
    "### Out-of-Scope Uses\n",
    "- Not suitable for factual question answering\n",
    "- Not designed for use in high-stakes domains (e.g., medical or legal)\n",
    "\n",
    "## Bias, Risks, and Limitations\n",
    "\n",
    "- May inherit biases from sarcasm datasets (e.g., cultural bias, gendered sarcasm)\n",
    "- Sarcasm is highly contextual; misinterpretations may occur\n",
    "\n",
    "## How to Get Started\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-3-mini-4k-instruct\", device_map=\"auto\")\n",
    "adapter = PeftModel.from_pretrained(base_model, \"sweatSmile/ak-phi3-mini-sarcasm-adapter\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-3-mini-4k-instruct\")\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=adapter, tokenizer=tokenizer)\n",
    "pipe(\"Why do we even have meetings on Fridays?\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
